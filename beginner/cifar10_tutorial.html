

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Training a Convolutional Neural Network for Image Classification &mdash; Cogitare Tutorials 1.0 documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/julia.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  
    <link rel="stylesheet" href="../_static/julia.css" type="text/css" />
  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Cogitare Tutorials 1.0 documentation" href="../index.html"/>
        <link rel="prev" title="Welcome to Cogitare Tutorials" href="../index.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

<a href="https://github.com/cogitare-ai/cogitare"><img style="z-index: 1; position: fixed; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/e7bbb0521b397edbd5fe43e7f760759336b5e05f/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677265656e5f3030373230302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_green_007200.png"></a>

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="http://tutorials.cogitare-ai.org/"><img src="../_static/logo-line.png" class="logo"></a>
        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Home</a></li>
</ul>
<p class="caption"><span class="caption-text">Beginner</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training a Convolutional Neural Network for Image Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#training-an-image-classifier">Training an image classifier</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#importing-and-declaring-global-variables">1. Importing and Declaring Global Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loading-and-normalizing-cifar10">2. Loading and normalizing CIFAR10</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-visualization">2.1 Data Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#define-a-convolution-neural-network">3. Define a Convolution Neural Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-the-model">4. Training the Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-evaluation">5. Model Evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#visualization">5.1 Visualization</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Cogitare Tutorials</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Training a Convolutional Neural Network for Image Classification</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/beginner/cifar10_tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document">
            
  <div class="section" id="training-a-convolutional-neural-network-for-image-classification">
<span id="sphx-glr-beginner-cifar10-tutorial-py"></span><h1>Training a Convolutional Neural Network for Image Classification<a class="headerlink" href="#training-a-convolutional-neural-network-for-image-classification" title="Permalink to this headline">¶</a></h1>
<p><em>Tutorial adapted from http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html</em></p>
<p>Generally, when you have to deal with image, text, audio or video data,
you can use standard python packages that load data into a numpy array.
Then you can convert this array into a <code class="docutils literal"><span class="pre">torch.*Tensor</span></code>.</p>
<ul class="simple">
<li>For images, packages such as Pillow, OpenCV are useful.</li>
<li>For audio, packages such as scipy and librosa</li>
<li>For text, either raw Python or Cython based loading, or NLTK and
SpaCy are useful.</li>
</ul>
<p>For this tutorial, we will use the CIFAR10 dataset. It has the classes:
<code class="docutils literal"><span class="pre">airplane</span></code>, <code class="docutils literal"><span class="pre">automobile</span></code>, <code class="docutils literal"><span class="pre">bird</span></code>, <code class="docutils literal"><span class="pre">cat</span></code>, <code class="docutils literal"><span class="pre">deer</span></code>, <code class="docutils literal"><span class="pre">dog</span></code>,
<code class="docutils literal"><span class="pre">frog</span></code>, <code class="docutils literal"><span class="pre">horse</span></code>, <code class="docutils literal"><span class="pre">ship</span></code>, <code class="docutils literal"><span class="pre">truck</span></code>. The images in CIFAR-10 are of
size 3x32x32, i.e.&nbsp;3-channel color images of 32x32 pixels in size.</p>
<div class="figure" id="id1">
<img alt="cifar" src="../_images/cifar10.png" />
<p class="caption"><span class="caption-text">cifar</span></p>
</div>
<div class="section" id="training-an-image-classifier">
<h2>Training an image classifier<a class="headerlink" href="#training-an-image-classifier" title="Permalink to this headline">¶</a></h2>
<p>We will do the following steps in order:</p>
<ol class="arabic simple">
<li>Import libraries and add model settings</li>
<li>Load and normalizing the CIFAR10 training and test datasets using
<code class="docutils literal"><span class="pre">torchvision</span></code></li>
<li>Define a Convolution Neural Network (forward)</li>
<li>Train the network on the training data</li>
<li>Test the network on the test data</li>
</ol>
<div class="section" id="importing-and-declaring-global-variables">
<h3>1. Importing and Declaring Global Variables<a class="headerlink" href="#importing-and-declaring-global-variables" title="Permalink to this headline">¶</a></h3>
<p>We start be importing all libraries that will be required in this
tutorial.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="kn">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>

<span class="kn">from</span> <span class="nn">cogitare.data</span> <span class="kn">import</span> <span class="n">DataSet</span><span class="p">,</span> <span class="n">AsyncDataLoader</span>
<span class="kn">from</span> <span class="nn">cogitare</span> <span class="kn">import</span> <span class="n">utils</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">cogitare.plugins</span> <span class="kn">import</span> <span class="n">EarlyStopping</span>
<span class="kn">from</span> <span class="nn">cogitare.metrics.classification</span> <span class="kn">import</span> <span class="n">accuracy</span>
<span class="kn">import</span> <span class="nn">cogitare</span>

<span class="kn">import</span> <span class="nn">argparse</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">pa</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span>  <span class="c1"># define a shortcut</span>

<span class="n">pa</span><span class="p">(</span><span class="s1">&#39;--batch-size&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Size of the training batch&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">pa</span><span class="p">(</span><span class="s1">&#39;--cuda&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;enable cuda&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">)</span>
<span class="n">pa</span><span class="p">(</span><span class="s1">&#39;--dropout&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;dropout rate in the input data&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">pa</span><span class="p">(</span><span class="s1">&#39;--learning-rate&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;learning rate&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">pa</span><span class="p">(</span><span class="s1">&#39;--max-epochs&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;limit the number of epochs in training&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>


<span class="c1"># load the model arguments</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">([])</span>


<span class="n">cogitare</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">set_cuda</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">cuda</span><span class="p">)</span>

<span class="n">CLASSES</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;plane&#39;</span><span class="p">,</span> <span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;deer&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;frog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;ship&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="loading-and-normalizing-cifar10">
<h3>2. Loading and normalizing CIFAR10<a class="headerlink" href="#loading-and-normalizing-cifar10" title="Permalink to this headline">¶</a></h3>
<p>Using <code class="docutils literal"><span class="pre">torchvision</span></code>, it’s extremely easy to load CIFAR10.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># The output of torchvision datasets are PILImage images of range [0, 1].</span>
<span class="c1"># We transform them to Tensors of normalized range [-1, 1]</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
     <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))])</span>

<span class="c1"># load the CIFAR 10 data</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                        <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="n">testset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                       <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">trainset</span><span class="o">.</span><span class="n">train_data</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
Files already downloaded and verified
&lt;class &#39;numpy.ndarray&#39;&gt;
</pre></div>
</div>
<p>Torchvision loads the data as numpy arrays.</p>
<p>We now create two datasets to hold the train and test sets.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">trainset</span><span class="o">.</span><span class="n">train_data</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">trainset</span><span class="o">.</span><span class="n">train_labels</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">batch2variable</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># B x W x H x C to B x C x W x W</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">to_variable</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">),</span> <span class="n">utils</span><span class="o">.</span><span class="n">to_variable</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># convert the trainset.train_labels to LongTensor, instead of python list</span>

<span class="n">data_train</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">([</span><span class="n">trainset</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">trainset</span><span class="o">.</span><span class="n">train_labels</span><span class="p">)],</span>
                     <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                     <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># use the async loader, to pre-load 8 batches ahead of the model</span>
<span class="c1"># each batch is then loaded and moved to a torch Variable</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">AsyncDataLoader</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">buffer_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span>
                             <span class="n">on_batch_loaded</span><span class="o">=</span><span class="n">batch2variable</span><span class="p">)</span>

<span class="n">data_test</span> <span class="o">=</span> <span class="n">DataSet</span><span class="p">([</span><span class="n">testset</span><span class="o">.</span><span class="n">test_data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">testset</span><span class="o">.</span><span class="n">test_labels</span><span class="p">)],</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">AsyncDataLoader</span><span class="p">(</span><span class="n">data_test</span><span class="p">,</span> <span class="n">buffer_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span>
                            <span class="n">on_batch_loaded</span><span class="o">=</span><span class="n">batch2variable</span><span class="p">)</span>

<span class="c1"># fill the data buffer</span>
<span class="n">data_train</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">data_test</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
&lt;class &#39;list&#39;&gt;
</pre></div>
</div>
<p>The train and test datasets are defined as a collection of tuples, each
tuple contains <code class="docutils literal"><span class="pre">(data,</span> <span class="pre">expected</span> <span class="pre">label)</span></code>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">data_train</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span>(Variable containing:
(0 ,0 ,.,.) =
  133  131  127  ...   167  154  142
  135  121  119  ...   180  163  143
  129  122  122  ...   148  122   95
      ...         ⋱        ...
  122  124  124  ...   152  147  122
  113  119  124  ...   127  112  111
   94   96  113  ...   102  104  107

(0 ,1 ,.,.) =
  115  106  106  ...   154  142  133
  112   92   93  ...   166  150  131
  102   87   91  ...   131  107   80
      ...         ⋱        ...
  105  103   99  ...   119  112   94
   94   96   98  ...    97   84   88
   76   74   87  ...    80   85   88

(0 ,2 ,.,.) =
   81   79   80  ...   129  119  114
   84   71   73  ...   134  124  116
   79   70   77  ...    97   81   68
      ...         ⋱        ...
   77   77   75  ...    95   83   65
   69   76   82  ...    70   58   64
   53   57   75  ...    53   63   71
     ⋮

(1 ,0 ,.,.) =
  216  196  209  ...    63  144  177
  227  215  204  ...   100  137  175
  218  223  213  ...    95  112  160
      ...         ⋱        ...
   22   43   57  ...   209  201  203
   23   31   53  ...   236  228  227
   27   23   47  ...   251  249  245

(1 ,1 ,.,.) =
  216  196  209  ...    63  144  177
  227  215  204  ...   100  137  175
  218  223  213  ...    95  112  160
      ...         ⋱        ...
   22   43   57  ...   209  201  203
   23   31   53  ...   236  228  227
   27   23   47  ...   251  249  245

(1 ,2 ,.,.) =
  216  196  209  ...    63  144  177
  227  215  204  ...   100  137  175
  218  223  213  ...    95  112  160
      ...         ⋱        ...
   22   43   57  ...   209  201  203
   23   31   53  ...   236  228  227
   27   23   47  ...   251  249  245
     ⋮

(2 ,0 ,.,.) =
  254  253  225  ...   241  247  246
  250  246  181  ...   180  241  241
  250  231  126  ...   102  218  242
      ...         ⋱        ...
   51   59   62  ...    53   57   61
   53   63   64  ...    55   57   63
   60   62   64  ...    55   52   57

(2 ,1 ,.,.) =
  255  255  238  ...   246  251  251
  254  253  194  ...   192  250  247
  255  240  142  ...   121  230  249
      ...         ⋱        ...
   88   86   83  ...    89   78   77
   87   86   83  ...    88   78   78
   88   85   82  ...    79   70   71

(2 ,2 ,.,.) =
  255  255  241  ...   255  255  255
  253  254  203  ...   205  252  251
  254  243  157  ...   142  237  254
      ...         ⋱        ...
  113  102   97  ...   111  104   96
  111  105  101  ...   112  103   97
  111  105   98  ...   104   99   96
...
     ⋮

(61,0 ,.,.) =
  255  177   72  ...     2    0    0
  255  182  110  ...     1    0    0
  255  194   88  ...     0    0    0
      ...         ⋱        ...
  103   60   78  ...    67   52   27
   97   59   69  ...    63   47   25
  119   91   90  ...    54   43   22

(61,1 ,.,.) =
  255  219  159  ...     1    0    0
  255  220  183  ...     1    0    0
  255  224  159  ...     1    0    0
      ...         ⋱        ...
  122   80   97  ...    90   74   39
  112   75   83  ...    84   66   35
  131  104  102  ...    67   55   29

(61,2 ,.,.) =
  255  235  190  ...     0    0    0
  255  233  209  ...     1    0    0
  255  231  182  ...     1    0    0
      ...         ⋱        ...
  139  105  118  ...   113   90   50
  131  101  106  ...   101   81   44
  148  125  117  ...    77   64   35
     ⋮

(62,0 ,.,.) =
   86   69   45  ...    30   31   34
   64   56   41  ...    29   29   31
   56   56   45  ...    30   27   31
      ...         ⋱        ...
  117  119  113  ...   133  132  134
  113  113  111  ...   119  124  129
  107   98   98  ...   117  119  113

(62,1 ,.,.) =
   78   65   51  ...    45   46   49
   61   57   48  ...    42   43   46
   53   56   48  ...    41   40   46
      ...         ⋱        ...
  132  136  130  ...   150  154  156
  123  128  128  ...   137  141  144
  115  110  113  ...   121  130  126

(62,2 ,.,.) =
   65   56   51  ...    48   49   52
   49   47   45  ...    46   46   49
   43   47   43  ...    45   44   49
      ...         ⋱        ...
   93   98   95  ...   121  112  120
   86   88   90  ...    97   99  110
   80   74   78  ...    88   93   94
     ⋮

(63,0 ,.,.) =
  130  139  150  ...   136  126  116
  126  138  156  ...   124  120  115
  131  142  155  ...   120  114  119
      ...         ⋱        ...
  154  150  137  ...   183  155  135
  157  145  142  ...   172  153  131
  142  138  145  ...   155  153  126

(63,1 ,.,.) =
  106  115  126  ...   119  105   92
  105  117  135  ...   105   99   91
  115  125  138  ...    99   93   96
      ...         ⋱        ...
  144  132  119  ...   164  145  130
  142  128  126  ...   152  142  128
  123  122  131  ...   136  142  123

(63,2 ,.,.) =
   76   85   96  ...    89   79   66
   73   86  104  ...    79   77   68
   82   93  106  ...    77   75   75
      ...         ⋱        ...
  109  100   87  ...   131  106   88
  109   96   93  ...   119  105   88
   91   89   98  ...   104  108   85
[torch.FloatTensor of size 64x3x32x32]
, Variable containing:
 6
 3
 3
 4
 9
 3
 5
 2
 4
 1
 6
 1
 4
 8
 7
 3
 0
 6
 1
 9
 0
 8
 1
 7
 1
 5
 9
 4
 9
 7
 5
 9
 6
 1
 9
 9
 5
 0
 3
 3
 9
 3
 8
 5
 2
 8
 5
 3
 9
 0
 4
 7
 3
 6
 8
 1
 7
 9
 8
 3
 8
 8
 4
 5
[torch.LongTensor of size 64]
)
</pre></div>
</div>
</div>
</div>
<div class="section" id="data-visualization">
<h2>2.1 Data Visualization<a class="headerlink" href="#data-visualization" title="Permalink to this headline">¶</a></h2>
<p>Let us show some of the training images, for fun.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">npimg</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">npimg</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">showlabels</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">qtd</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">qtd</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%10s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">CLASSES</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">j</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">4</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">imshow</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">16</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
<span class="n">showlabels</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_cifar10_tutorial_001.png" class="align-center" src="../_images/sphx_glr_cifar10_tutorial_001.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
     <span class="n">horse</span>     <span class="n">horse</span>       <span class="n">dog</span>     <span class="n">truck</span>

       <span class="n">car</span>      <span class="n">deer</span>       <span class="n">dog</span>       <span class="n">cat</span>

     <span class="n">plane</span>      <span class="n">deer</span>     <span class="n">horse</span>     <span class="n">plane</span>

     <span class="n">horse</span>      <span class="n">bird</span>       <span class="n">dog</span>      <span class="n">ship</span>
</pre></div>
</div>
</div>
<div class="section" id="define-a-convolution-neural-network">
<h2>3. Define a Convolution Neural Network<a class="headerlink" href="#define-a-convolution-neural-network" title="Permalink to this headline">¶</a></h2>
<p>In this section, we’ll define the forward method of the Cogitare Model.
In Cogitare, you must implement two methods in the model: <strong>forward</strong>
and <strong>loss</strong>.</p>
<p>This is a Convolutional Neural Network (CNN) for Image Classification.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># in this sample, each batch will be a tuple</span>
        <span class="c1"># containing (input_batch, expected_batch)</span>
        <span class="c1"># in forward in are only interested in input so that we</span>
        <span class="c1"># can ignore the second item of the tuple</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># in this sample, each batch will be a tuple</span>
        <span class="c1"># containing (input_batch, expected_batch)</span>
        <span class="c1"># in loss in are only interested in expected so that</span>
        <span class="c1"># we can ignore the first item of the tuple</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">expected</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
</pre></div>
</div>
<p>The model class is simple; it only requires de forward and loss methods.
By default, Cogitare will backward the loss returned by the loss()
method, and optimize the model parameters.</p>
</div>
<div class="section" id="training-the-model">
<h2>4. Training the Model<a class="headerlink" href="#training-the-model" title="Permalink to this headline">¶</a></h2>
<p>We first define the model optimizer for training the model.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">cnn</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">cnn</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
<p>We now add the default plugins to watch the training status. The default
plugin includes:</p>
<ul class="simple">
<li>Progress bar per batch and epoch</li>
<li>Plot training and validation losses (if validation_dataset is
present)</li>
<li>Log training loss</li>
</ul>
<p>And some extra plugins.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">cnn</span><span class="o">.</span><span class="n">register_default_plugins</span><span class="p">()</span>

<span class="n">early</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">max_tries</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s1">&#39;/tmp/model.pt&#39;</span><span class="p">)</span>
<span class="c1"># after 5 epochs without decreasing the loss, stop the</span>
<span class="c1"># training and the best model is saved at /tmp/model.pt</span>

<span class="c1"># the plugin will execute in the end of each epoch</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">register_plugin</span><span class="p">(</span><span class="n">early</span><span class="p">,</span> <span class="s1">&#39;on_end_epoch&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We can now run the training:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span><span class="p">:</span>
    <span class="n">cnn</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">cnn</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_cifar10_tutorial_002.png" class="align-center" src="../_images/sphx_glr_cifar10_tutorial_002.png" />
</div>
<div class="section" id="model-evaluation">
<h2>5. Model Evaluation<a class="headerlink" href="#model-evaluation" title="Permalink to this headline">¶</a></h2>
<p>We now check the model loss and accuracy on the test set:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># evaluate the model loss and accuracy over the validation dataset</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">evaluate_with_metrics</span><span class="p">(</span><span class="n">data_test</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">cnn</span><span class="o">.</span><span class="n">metric_loss</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">model_accuracy</span><span class="p">})</span>

<span class="c1"># the metrics is an dict mapping the metric name (loss or accuracy, in this sample) to a list of the accuracy output</span>
<span class="c1"># we have a measurement per batch. So, to have a value of the full dataset, we take the mean value:</span>

<span class="n">metrics_mean</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="k">for</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]):</span>
    <span class="n">metrics_mean</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">loss</span>
    <span class="n">metrics_mean</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">acc</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">qtd</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Loss: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics_mean</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">qtd</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics_mean</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">qtd</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="n">Loss</span><span class="p">:</span> <span class="mf">1.2460897301252072</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.5852363782051282</span>
</pre></div>
</div>
<div class="section" id="visualization">
<h3>5.1 Visualization<a class="headerlink" href="#visualization" title="Permalink to this headline">¶</a></h3>
<p>To check how the model behaves, we can plot the images, the expected and
predicted labels</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>

<span class="n">imshow</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">16</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_cifar10_tutorial_003.png" class="align-center" src="../_images/sphx_glr_cifar10_tutorial_003.png" />
<p>We forward the data to get the model output to the batch above.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">predict</span><span class="p">((</span><span class="n">images</span><span class="p">,</span> <span class="bp">None</span><span class="p">))</span>
<span class="c1"># remember that forward method expect a tuple, where the</span>
<span class="c1"># first item contains the data to be passed in the net</span>
<span class="n">predicted</span><span class="o">.</span><span class="n">shape</span>

<span class="n">_</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Predicted:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">showlabels</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">[:</span><span class="mi">16</span><span class="p">],</span> <span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="n">Predicted</span><span class="p">:</span>

      <span class="n">frog</span>       <span class="n">dog</span>      <span class="n">ship</span>       <span class="n">dog</span>

     <span class="n">horse</span>     <span class="n">horse</span>      <span class="n">ship</span>     <span class="n">horse</span>

     <span class="n">truck</span>      <span class="n">deer</span>      <span class="n">ship</span>       <span class="n">car</span>

       <span class="n">dog</span>       <span class="n">car</span>     <span class="n">truck</span>       <span class="n">dog</span>
</pre></div>
</div>
<p><strong>Total running time of the script:</strong> ( 4 minutes  29.314 seconds)</p>
<div class="sphx-glr-footer docutils container">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/cifar10_tutorial.py" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">cifar10_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/cifar10_tutorial.ipynb" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">cifar10_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="../index.html" class="btn btn-neutral" title="Welcome to Cogitare Tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Aron Bordin.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>